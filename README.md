# Grammar Checking Model

I have used a transformer model named BERT (Bidirectional Encoder Representations for Transformers) to design this system that analyses and predicts grammatical correctness.
This was developed using the PyTorch and TensorFlow frameworks, leveraging their capabilities for efficient computation and neural network training. 
Pre-trained BERT model weights were loaded and fine-tuned on the Corpus of Linguistic Acceptability (CoLA) dataset, which contains sentences labeled for grammatical correctness. The system's implementation encompassed data preprocessing, model initialization, training loop, evaluation, and testing stages, each meticulously designed to ensure the system's effectiveness in grammar checking tasks.

Snippet of a sample output - 

![image](https://github.com/user-attachments/assets/cb18743a-8bf6-426e-8a09-4b1da8092cc1)

